-- GitTables 1M Evaluation: FineType on sampled corpus with annotations
-- =============================================================================
-- Uses pre-extracted metadata from extract_metadata_1m.py
-- Reads sampled parquet files, unpivots, classifies with FineType,
-- compares against Schema.org/DBpedia ground truth annotations.
--
-- Usage: duckdb -unsigned < eval/gittables/eval_1m.sql
-- Prerequisites:
--   1. python3 eval/gittables/extract_metadata_1m.py  (generates metadata CSVs)
--   2. Topic zips extracted to /home/hugh/git-tables/topics/{topic}/

SET threads = 8;
SET memory_limit = '4GB';

LOAD '/home/hugh/github/noon-org/finetype/target/release/finetype_duckdb.duckdb_extension';

.mode box
.timer on

-- ═══════════════════════════════════════════════════════════════════════════════
-- 1. LOAD PRE-EXTRACTED METADATA
-- ═══════════════════════════════════════════════════════════════════════════════

.print ''
.print '═══════════════════════════════════════════════════════════════════'
.print '          GITTABLES 1M - LOADING METADATA                        '
.print '═══════════════════════════════════════════════════════════════════'

CREATE OR REPLACE TABLE catalog AS
SELECT * FROM read_csv('/home/hugh/git-tables/eval_output/catalog.csv', auto_detect=true);

CREATE OR REPLACE TABLE metadata AS
SELECT * FROM read_csv('/home/hugh/git-tables/eval_output/metadata.csv', auto_detect=true);

SELECT
    (SELECT sum(total_tables) FROM catalog) AS total_corpus_tables,
    (SELECT count(DISTINCT topic) FROM catalog) AS total_topics,
    count(*) AS sampled_tables,
    sum(CASE WHEN n_annotated_cols > 0 THEN 1 ELSE 0 END) AS annotated_tables,
    ROUND(sum(CASE WHEN n_annotated_cols > 0 THEN 1 ELSE 0 END) * 100.0 / count(*), 1) AS annotation_pct,
    sum(n_annotated_cols) AS total_annotated_cols
FROM metadata;

-- Flatten annotations: one row per (table, column, gt_label)
CREATE OR REPLACE TABLE ground_truth AS
SELECT
    m.topic,
    m.table_name,
    m.file_path,
    j.key AS col_name,
    j.value AS gt_label
FROM metadata m,
LATERAL (
    SELECT
        unnest(json_keys(m.annotations_json::JSON)) AS key,
        unnest(json_extract_string(m.annotations_json::JSON, '$.*'))
) j(key, value)
WHERE m.annotations_json IS NOT NULL AND m.annotations_json != '';

SELECT
    count(*) AS total_gt_annotations,
    count(DISTINCT gt_label) AS unique_gt_labels,
    count(DISTINCT topic) AS topics_with_gt
FROM ground_truth;

.print ''
.print '--- Top 20 ground truth labels ---'
SELECT gt_label, count(*) AS columns
FROM ground_truth
GROUP BY gt_label
ORDER BY columns DESC
LIMIT 20;

-- ═══════════════════════════════════════════════════════════════════════════════
-- 2. LOAD PRE-EXTRACTED COLUMN VALUES
-- ═══════════════════════════════════════════════════════════════════════════════
-- Generated by: python3 eval/gittables/prepare_1m_values.py

.print ''
.print '═══════════════════════════════════════════════════════════════════'
.print '          LOADING COLUMN VALUES                                   '
.print '═══════════════════════════════════════════════════════════════════'

CREATE OR REPLACE TABLE column_values AS
SELECT * FROM read_parquet('/home/hugh/git-tables/eval_output/column_values.parquet');

SELECT
    count(*) AS total_values,
    count(DISTINCT topic || '/' || table_name) AS tables,
    count(DISTINCT topic || '/' || table_name || '/' || col_name) AS columns
FROM column_values;

-- ═══════════════════════════════════════════════════════════════════════════════
-- 3. CLASSIFY with FineType
-- ═══════════════════════════════════════════════════════════════════════════════

.print ''
.print '--- Running FineType classification ---'

CREATE OR REPLACE TABLE classified AS
SELECT
    topic,
    table_name,
    col_name,
    col_value,
    finetype(col_value) AS ft_label
FROM column_values;

SELECT count(*) AS values_classified FROM classified;

-- Per-column majority vote
CREATE OR REPLACE TABLE column_predictions AS
WITH vote_counts AS (
    SELECT
        topic,
        table_name,
        col_name,
        ft_label,
        count(*) AS votes,
        count(*) OVER (PARTITION BY topic, table_name, col_name) AS total_votes
    FROM classified
    GROUP BY topic, table_name, col_name, ft_label
),
ranked AS (
    SELECT *,
           row_number() OVER (PARTITION BY topic, table_name, col_name ORDER BY votes DESC) AS rk
    FROM vote_counts
)
SELECT
    topic,
    table_name,
    col_name,
    ft_label AS predicted_label,
    votes,
    total_votes,
    ROUND(votes * 100.0 / total_votes, 1) AS vote_pct
FROM ranked
WHERE rk = 1;

SELECT
    count(*) AS total_columns,
    count(DISTINCT topic) AS topics_covered,
    count(DISTINCT predicted_label) AS unique_ft_predictions
FROM column_predictions;

-- ═══════════════════════════════════════════════════════════════════════════════
-- 4. JOIN PREDICTIONS WITH GROUND TRUTH
-- ═══════════════════════════════════════════════════════════════════════════════

.print ''
.print '═══════════════════════════════════════════════════════════════════'
.print '          GROUND TRUTH COMPARISON                                 '
.print '═══════════════════════════════════════════════════════════════════'

CREATE OR REPLACE TABLE eval_results AS
SELECT
    cp.topic,
    cp.table_name,
    cp.col_name,
    cp.predicted_label,
    cp.vote_pct,
    gt.gt_label,
    split_part(cp.predicted_label, '.', 1) AS ft_domain
FROM column_predictions cp
JOIN ground_truth gt ON cp.topic = gt.topic
    AND cp.table_name = gt.table_name
    AND cp.col_name = gt.col_name;

SELECT
    count(*) AS columns_with_gt,
    count(DISTINCT gt_label) AS unique_gt_labels,
    count(DISTINCT predicted_label) AS unique_ft_predictions,
    count(DISTINCT topic) AS topics
FROM eval_results;

-- Domain mapping for accuracy measurement
CREATE OR REPLACE TABLE type_mapping AS
SELECT * FROM (VALUES
    ('email',       'identity'),
    ('url',         'technology'),
    ('date',        'datetime'),
    ('start date',  'datetime'),
    ('end date',    'datetime'),
    ('start time',  'datetime'),
    ('end time',    'datetime'),
    ('time',        'datetime'),
    ('created',     'datetime'),
    ('updated',     'datetime'),
    ('year',        'datetime'),
    ('postal code', 'geography'),
    ('zip code',    'geography'),
    ('country',     'geography'),
    ('state',       'geography'),
    ('city',        'geography'),
    ('id',          'technology'),
    ('name',        'identity'),
    ('percentage',  'representation'),
    ('age',         'representation'),
    ('price',       'representation'),
    ('weight',      'representation'),
    ('height',      'representation'),
    ('depth',       'representation'),
    ('width',       'representation'),
    ('length',      'representation'),
    ('duration',    'datetime'),
    ('gender',      'identity'),
    ('author',      'identity'),
    ('description', 'representation'),
    ('title',       'representation'),
    ('abstract',    'representation'),
    ('comment',     'representation'),
    ('status',      'representation'),
    ('category',    'representation'),
    ('type',        'representation'),
    ('telephone',   'identity'),
    ('currency',    'representation'),
    ('latitude',    'geography'),
    ('longitude',   'geography'),
    ('address',     'geography'),
    ('brand',       'identity'),
    ('color',       'representation'),
    ('language',    'representation'),
    ('coordinates', 'geography')
) AS t(gt_label, expected_ft_domain);

-- ═══════════════════════════════════════════════════════════════════════════════
-- 5. ANALYSIS RESULTS
-- ═══════════════════════════════════════════════════════════════════════════════

.print ''
.print '═══════════════════════════════════════════════════════════════════'
.print '          ANALYSIS RESULTS                                        '
.print '═══════════════════════════════════════════════════════════════════'

-- 5a. FineType domain distribution (all profiled columns)
.print ''
.print '--- FineType domain distribution (all columns) ---'
SELECT
    split_part(predicted_label, '.', 1) AS ft_domain,
    count(*) AS columns,
    ROUND(count(*) * 100.0 / sum(count(*)) OVER (), 1) AS pct
FROM column_predictions
GROUP BY ft_domain
ORDER BY columns DESC;

-- 5b. Top 30 FineType predictions
.print ''
.print '--- Top 30 FineType predictions ---'
SELECT
    predicted_label,
    count(*) AS columns,
    ROUND(count(*) * 100.0 / sum(count(*)) OVER (), 1) AS pct,
    ROUND(avg(vote_pct), 1) AS avg_confidence
FROM column_predictions
GROUP BY predicted_label
ORDER BY columns DESC
LIMIT 30;

-- 5c. GT label → FineType domain mapping accuracy
.print ''
.print '--- Domain-level accuracy for mapped types ---'
SELECT
    tm.expected_ft_domain,
    count(*) AS total_columns,
    sum(CASE WHEN er.ft_domain = tm.expected_ft_domain THEN 1 ELSE 0 END) AS correct,
    ROUND(sum(CASE WHEN er.ft_domain = tm.expected_ft_domain THEN 1 ELSE 0 END) * 100.0 / count(*), 1) AS accuracy_pct
FROM eval_results er
JOIN type_mapping tm ON er.gt_label = tm.gt_label
GROUP BY tm.expected_ft_domain
ORDER BY total_columns DESC;

-- 5d. Detailed: GT label × FineType prediction
.print ''
.print '--- GT label → FineType prediction (top 40 by frequency) ---'
SELECT
    er.gt_label,
    er.predicted_label,
    count(*) AS columns,
    ROUND(avg(er.vote_pct), 1) AS avg_conf
FROM eval_results er
GROUP BY er.gt_label, er.predicted_label
HAVING count(*) >= 5
ORDER BY er.gt_label, columns DESC
LIMIT 40;

-- 5e. Per-topic type diversity
.print ''
.print '--- Per-topic type diversity (top 20 topics by column count) ---'
SELECT
    topic,
    count(*) AS columns,
    count(DISTINCT predicted_label) AS unique_types,
    count(DISTINCT split_part(predicted_label, '.', 1)) AS unique_domains
FROM column_predictions
GROUP BY topic
ORDER BY columns DESC
LIMIT 20;

-- 5f. Per-topic dominant domain
.print ''
.print '--- Per-topic dominant FineType domain ---'
WITH topic_domains AS (
    SELECT
        topic,
        split_part(predicted_label, '.', 1) AS ft_domain,
        count(*) AS cnt,
        count(*) OVER (PARTITION BY topic) AS total
    FROM column_predictions
    GROUP BY topic, ft_domain
),
ranked AS (
    SELECT *,
           row_number() OVER (PARTITION BY topic ORDER BY cnt DESC) AS rk,
           ROUND(cnt * 100.0 / total, 1) AS pct
    FROM topic_domains
)
SELECT topic, ft_domain AS dominant_domain, cnt AS columns, pct, total AS total_cols
FROM ranked
WHERE rk = 1
ORDER BY total_cols DESC
LIMIT 30;

-- 5g. Low confidence predictions
.print ''
.print '--- Low confidence predictions (vote_pct < 60%) ---'
SELECT
    predicted_label,
    count(*) AS low_conf_columns,
    ROUND(avg(vote_pct), 1) AS avg_vote_pct
FROM column_predictions
WHERE vote_pct < 60
GROUP BY predicted_label
ORDER BY low_conf_columns DESC
LIMIT 20;

-- 5h. Perfect agreement predictions
.print ''
.print '--- Perfect agreement by domain (vote_pct = 100%) ---'
SELECT
    split_part(predicted_label, '.', 1) AS ft_domain,
    count(*) AS perfect_columns,
    ROUND(count(*) * 100.0 / sum(count(*)) OVER (), 1) AS pct
FROM column_predictions
WHERE vote_pct = 100
GROUP BY ft_domain
ORDER BY perfect_columns DESC;

-- 5i. Unmapped GT labels (gaps in taxonomy)
.print ''
.print '--- GT labels with NO domain mapping (potential taxonomy gaps) ---'
SELECT
    er.gt_label,
    count(*) AS columns,
    list(DISTINCT er.ft_domain ORDER BY er.ft_domain) AS ft_domains_seen
FROM eval_results er
LEFT JOIN type_mapping tm ON er.gt_label = tm.gt_label
WHERE tm.gt_label IS NULL
GROUP BY er.gt_label
ORDER BY columns DESC
LIMIT 25;

-- 5j. Overall domain accuracy
.print ''
.print '--- Overall mapped domain accuracy ---'
SELECT
    'Mapped types (domain match)' AS metric,
    count(*) AS total,
    sum(CASE WHEN er.ft_domain = tm.expected_ft_domain THEN 1 ELSE 0 END) AS correct,
    ROUND(sum(CASE WHEN er.ft_domain = tm.expected_ft_domain THEN 1 ELSE 0 END) * 100.0 / count(*), 1) AS accuracy_pct
FROM eval_results er
JOIN type_mapping tm ON er.gt_label = tm.gt_label;

-- 5k. Comparison with benchmark subset
.print ''
.print '--- Benchmark comparison metrics ---'
.print '    (Benchmark subset: 2,384 columns, 42.2% domain accuracy)'
.print '    (1M sample results above)'

-- 5l. Throughput
.print ''
.print '--- Throughput summary ---'
SELECT
    count(*) AS total_values_classified,
    count(DISTINCT topic || '/' || table_name || '/' || col_name) AS total_columns,
    count(DISTINCT topic || '/' || table_name) AS total_tables,
    count(DISTINCT topic) AS total_topics
FROM classified;

.print ''
.print '--- Evaluation complete ---'
